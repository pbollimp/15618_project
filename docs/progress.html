

    <section class="main-content">
      <h2>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Project Checkpoint</b></h2>

<h3>Problem summary</h3>

<p>
We are going to optimize the task of searching for the optimal hyper parameters and architecture for a fixed machine learning problem of image classification in CIFAR-10 dataset. There are multiple approaches (such as random search, bayesian optimization, evolutionary optimization, reinforcement learning) that can be used in order to solve this task. Additionally, the hyper parameter space is huge (learning rate, loss function, batch size, number of hidden units and layers, activation functions just to name a few). We aim to explore and speed up different techniques and compare the resulting model accuracy along with the time taken by the techniques to find the best model.
</p>


<h3> Updates </h3>

<h4> Setting up the framework </h4>

<p> We realized that the task of image segmentation (as originally proposed) takes a long time to train for different hyperparameters and due to our resource constraints, we modified our task to be  image classification on CIFAR-10 dataset. This presents a good trade-off between accuracy of the model when tested with different hyperparameters and the time it takes to train the model. This is further supported by fact that the current research in this area also uses this dataset for benchmarking. </p>


<h4> Baselines </h4>

<p> Random search was trivially implemented. We decided that we are not going to implement grid search since it is just a brute force technique and does not provide any insight in terms of the techniques for parallelization of the algorithm or the performance. We are instead implementing and parallelizing  Monte Carlo Tree Search on the tree generated by the hyperparameter search space. This is one of the techniques in Tree-structured Parzen Estimator Approach (TPE) used for hyperparameter optimization. </p>

<h4> Main Algorithms </h4>

<p>We are implementing the parallelization approach for Bayesian Optimisation by using asynchronous updates and we are also parallelizing the Thompson Sampling step in the algorithm.
</p>

<p>For the evolutionary search task, we came up with an idea to parallelize through fork-join model. The main thread would create multiple child threads that would get different hyperparameter tuples to test the model on by sampling the random noise in parallel. They then communicate together to rank the hyperparameter tuples by their performance and to update them (replacing the worst-performing hyperparameter tuples with new hyperparameter tuples). This is repeated until a satisfactory performance is reached or until the algorithm performance is no longer improving. We are going to experiment with multiple threads and iterations of the algorithm along with different starting architectures (larger architecture would have many parameters to learn but would give better accuracy).</p>

<p>For the reinforcement learning algorithm, we fixed on the Advantage-Actor-Critic (A2C) algorithm. We can first easily start to parallelize it by modifying it into an Asynchronous Advantage Actor Critic which is shown to work by executing a set of environments in parallel to increase the diversity of training data and with gradient updates performed in a Hogwild! Procedure. Then, we are going to extend this framework to have multiple actors which work on the environments in parallel and have a master thread generate the actions for all environments by sampling from the current policy. We are planning to experiment with both synchronous and asynchronous communication between the master thread and other threads.</p>

<h3> Goals </h3>
<p>
We are behind by a week from our proposed schedule and thus do not have results at this point in time. But, we plan to meet all of our proposed goals for the final. 
</p>

<p>
Our goal to show at the poster session is to still the same as our proposal: to show the plots that illustrate the speed up of different techniques and also compare the resulting model accuracy along with the time taken by all these techniques to find the best model.
</p>

<p> One of the major concern that we have is presented in the report that we submitted in gradescope </p>


<h3>Updated Schedule</h3>
<p>More details about the specifics of the algorithms are given above. </p>


<li> Week 11/19 - 11/25: Finishing the implementation for Monte Carlo Tree Search algorithm [Priyatham]. Finishing the implementation for Bayesian Optimization algorithm [Mohit]</li>

<li> Week 11/26 - 12/2: Implementing the sequential version of evolutionary search and parallelizing it [Priyatham]. Implementing our version of A3C RL algorithm [Mohit]. Analyzing the performance and identify the bottlenecks of both algorithms [Both] </li>
<li> Week 12/3 - 12/9: More analysis and making further optimizations to improve performance [Both] </li>
<li> Week 12/10 - 12/15: Wrapping up the experiments for all and plotting the speedups and comparative performance with respect to time and accuracy. Creating report and poster. </li>



<footer class="site-footer">
<span class="site-footer-owner"><a href="https://github.com/pbollimp/Meta-Machine-Learning">Meta Machine Learning</a> is maintained by <a href="https://github.com/pbollimp">Priyatham</a> & <a href="https://github.com/mdsingh2013">Mohit</a>.</span>

<span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
</footer>

  
</section>
